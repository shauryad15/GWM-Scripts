{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFVzvh89wkND"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9B_LyPICwzah",
    "outputId": "19598316-752e-4cf8-c53d-f51ce694b89e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "zZuY0ADUy6dv",
    "outputId": "3384f4df-bbdd-45a5-fb35-877e3956c21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-02 15:06:27--  http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.142.128, 2607:f8b0:400e:c08::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.142.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 513324920 (490M) [application/x-tar]\n",
      "Saving to: ‘vgg_16_2016_08_28.tar.gz’\n",
      "\n",
      "vgg_16_2016_08_28.t 100%[===================>] 489.54M  64.0MB/s    in 8.4s    \n",
      "\n",
      "2019-03-02 15:06:35 (58.4 MB/s) - ‘vgg_16_2016_08_28.tar.gz’ saved [513324920/513324920]\n",
      "\n",
      "vgg_16.ckpt\n",
      "vgg_16.ckpt\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\n",
    "!tar -xvf vgg_16_2016_08_28.tar.gz\n",
    "!rm vgg_16_2016_08_28.tar.gz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0AmIzSuKzCxZ",
    "outputId": "5cf26197-acb7-4e10-98fe-ced39309be0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-02-26 17:14:45--  http://cs231n.stanford.edu/coco-animals.zip\n",
      "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
      "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 181492696 (173M) [application/zip]\n",
      "Saving to: ‘coco-animals.zip’\n",
      "\n",
      "coco-animals.zip    100%[===================>] 173.08M  12.4MB/s    in 17s     \n",
      "\n",
      "2019-02-26 17:15:02 (10.2 MB/s) - ‘coco-animals.zip’ saved [181492696/181492696]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs231n.stanford.edu/coco-animals.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Xo7uc6R1BOd"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Km5OqM7oEU2Z",
    "outputId": "b834fd9d-00df-4bbb-f34a-a6e9253e1f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear  bird  cat  dog  giraffe  horse  sheep  zebra\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/gdrive/My Drive/coco animal dataset/coco-animals/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2XsDyBJ8-2Z"
   },
   "outputs": [],
   "source": [
    "#VGG Mean\n",
    "VGG_MEAN = [123.68, 116.78, 103.94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDrMcQwi9lCU"
   },
   "outputs": [],
   "source": [
    "def list_images(directory):\n",
    "    \"\"\"\n",
    "    Get all the images and labels in directory/label/*.jpg\n",
    "    \"\"\"\n",
    "    labels = os.listdir(directory)\n",
    "    # Sort the labels so that training and validation get them in the same order\n",
    "    labels.sort()\n",
    "\n",
    "    files_and_labels = []\n",
    "    for label in labels:\n",
    "        for f in os.listdir(os.path.join(directory, label)):\n",
    "            files_and_labels.append((os.path.join(directory, label, f), label))\n",
    "\n",
    "    filenames, labels = zip(*files_and_labels)\n",
    "    filenames = list(filenames)\n",
    "    labels = list(labels)\n",
    "    unique_labels = list(set(labels))\n",
    "\n",
    "    label_to_int = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        label_to_int[label] = i\n",
    "\n",
    "    labels = [label_to_int[l] for l in labels]\n",
    "\n",
    "    return filenames, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5zYynU29sV6"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(sess, correct_prediction, is_training, dataset_init_op):\n",
    "    \"\"\"\n",
    "    Check the accuracy of the model on either train or val (depending on dataset_init_op).\n",
    "    \"\"\"\n",
    "    # Initialize the correct dataset\n",
    "    sess.run(dataset_init_op)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    while True:\n",
    "        try:\n",
    "            correct_pred = sess.run(correct_prediction, {is_training: False})\n",
    "            num_correct += correct_pred.sum()\n",
    "            num_samples += correct_pred.shape[0]\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # Return the fraction of datapoints that were correctly classified\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgNlKEsz9yPs"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Get the list of filenames and corresponding list of labels for training et validation\n",
    "    train_filenames, train_labels = list_images('/content/gdrive/My Drive/coco animal dataset/coco-animals/train')\n",
    "    val_filenames, val_labels = list_images('/content/gdrive/My Drive/coco animal dataset/coco-animals/val')\n",
    "    assert set(train_labels) == set(val_labels),\\\n",
    "           \"Train and val labels don't correspond:\\n{}\\n{}\".format(set(train_labels),\n",
    "                                                                   set(val_labels))\n",
    "\n",
    "    num_classes = len(set(train_labels))\n",
    "\n",
    "    #Define computation graph\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        \n",
    "        \n",
    "        # Preprocessing (for both training and validation):\n",
    "        # (1) Decode the image from jpg format\n",
    "        # (2) Resize the image so its smaller side is 256 pixels long\n",
    "        def _parse_function(filename, label):\n",
    "            image_string = tf.read_file(filename)\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3)          # (1)\n",
    "            image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "            smallest_side = 256.0\n",
    "            height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "            height = tf.to_float(height)\n",
    "            width = tf.to_float(width)\n",
    "\n",
    "            scale = tf.cond(tf.greater(height, width),\n",
    "                            lambda: smallest_side / width,\n",
    "                            lambda: smallest_side / height)\n",
    "            new_height = tf.to_int32(height * scale)\n",
    "            new_width = tf.to_int32(width * scale)\n",
    "\n",
    "            resized_image = tf.image.resize_images(image, [new_height, new_width])  # (2)\n",
    "            return resized_image, label\n",
    "\n",
    "        # Preprocessing (for training)\n",
    "        # (3) Take a random 224x224 crop to the scaled image\n",
    "        # (4) Horizontally flip the image with probability 1/2\n",
    "        # (5) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def training_preprocess(image, label):\n",
    "            crop_image = tf.random_crop(image, [224, 224, 3])                       # (3)\n",
    "            flip_image = tf.image.random_flip_left_right(crop_image)                # (4)\n",
    "\n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = flip_image - means                                     # (5)\n",
    "\n",
    "            return centered_image, label\n",
    "\n",
    "        # Preprocessing (for validation)\n",
    "        # (3) Take a central 224x224 crop to the scaled image\n",
    "        # (4) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def val_preprocess(image, label):\n",
    "            crop_image = tf.image.resize_image_with_crop_or_pad(image, 224, 224)    # (3)\n",
    "\n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = crop_image - means                                     # (4)\n",
    "\n",
    "            return centered_image, label\n",
    "\n",
    "        # Training dataset\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "        train_dataset = train_dataset.map(_parse_function,\n",
    "            num_parallel_calls=4)\n",
    "        train_dataset = train_dataset.map(training_preprocess,\n",
    "            num_parallel_calls=4)\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)  # don't forget to shuffle\n",
    "        batched_train_dataset = train_dataset.batch(32)\n",
    "\n",
    "        # Validation dataset\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "        val_dataset = val_dataset.map(_parse_function,\n",
    "            num_parallel_calls=4)\n",
    "        val_dataset = val_dataset.map(val_preprocess,\n",
    "            num_parallel_calls=4)\n",
    "        batched_val_dataset = val_dataset.batch(32)\n",
    "\n",
    "        #Iterator\n",
    "        iterator = tf.data.Iterator.from_structure(batched_train_dataset.output_types,\n",
    "                                                           batched_train_dataset.output_shapes)\n",
    "        images, labels = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(batched_train_dataset)\n",
    "        val_init_op = iterator.make_initializer(batched_val_dataset)\n",
    "\n",
    "        # Indicates whether we are in training or in test mode\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        #Get pretrained model\n",
    "        vgg = tf.contrib.slim.nets.vgg\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=5e-4)):\n",
    "            logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=is_training,\n",
    "                                   dropout_keep_prob=0.5)\n",
    "\n",
    "        # Specify where the model checkpoint is (pretrained weights).\n",
    "        model_path = '/content/gdrive/My Drive/VGG16/vgg_16.ckpt'\n",
    "        assert(os.path.isfile(model_path))\n",
    "\n",
    "        # Restore only the layers up to fc7 (included)\n",
    "        variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "        init_fn = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "\n",
    "        # Initialization operation from scratch for the new \"fc8\" layers\n",
    "        fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "        fc8_init = tf.variables_initializer(fc8_variables)\n",
    "\n",
    "        tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        loss = tf.losses.get_total_loss()\n",
    "\n",
    "        fc8_optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "        fc8_train_op = fc8_optimizer.minimize(loss, var_list=fc8_variables)\n",
    "\n",
    "        full_optimizer = tf.train.GradientDescentOptimizer(1e-5)\n",
    "        full_train_op = full_optimizer.minimize(loss)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        prediction = tf.to_int32(tf.argmax(logits, 1))\n",
    "        correct_prediction = tf.equal(prediction, labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        tf.get_default_graph().finalize()\n",
    "\n",
    "    \n",
    "    \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        init_fn(sess)  # load the pretrained weights\n",
    "        sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "        \n",
    "\n",
    "        # Update only the last layer for a few epochs.\n",
    "        for epoch in range(10):\n",
    "            # Run an epoch over the training data.\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, 10))\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _ = sess.run(fc8_train_op, {is_training: True})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "\n",
    "            # Check accuracy on the train and val sets every epoch.\n",
    "            train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            print('Train accuracy: %f' % train_acc)\n",
    "            print('Val accuracy: %f\\n' % val_acc)\n",
    "\n",
    "\n",
    "        # Train the entire model for a few more epochs, continuing with the *same* weights.\n",
    "        for epoch in range(10):\n",
    "            print('Starting epoch %d / %d' % (epoch + 1,10))\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _ = sess.run(full_train_op, {is_training: True})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "\n",
    "            # Check accuracy on the train and val sets every epoch\n",
    "            train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            print('Train accuracy: %f' % train_acc)\n",
    "            print('Val accuracy: %f\\n' % val_acc)\n",
    "         \n",
    "        saver.save(sess, '/content/gdrive/My Drive/VGG16/coco_vgg16')\n",
    "        print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1686
    },
    "colab_type": "code",
    "id": "wjf7ZLY0_qGg",
    "outputId": "b1ae9815-d663-4ebc-a6f1-ea0f4d9bf3b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-032acdb2ddf8>:31: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-9-032acdb2ddf8>:37: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/VGG16/vgg_16.ckpt\n",
      "Starting epoch 1 / 10\n",
      "Train accuracy: 0.575000\n",
      "Val accuracy: 0.595000\n",
      "\n",
      "Starting epoch 2 / 10\n",
      "Train accuracy: 0.736250\n",
      "Val accuracy: 0.725000\n",
      "\n",
      "Starting epoch 3 / 10\n",
      "Train accuracy: 0.776250\n",
      "Val accuracy: 0.765000\n",
      "\n",
      "Starting epoch 4 / 10\n",
      "Train accuracy: 0.806250\n",
      "Val accuracy: 0.800000\n",
      "\n",
      "Starting epoch 5 / 10\n",
      "Train accuracy: 0.812500\n",
      "Val accuracy: 0.790000\n",
      "\n",
      "Starting epoch 6 / 10\n",
      "Train accuracy: 0.833750\n",
      "Val accuracy: 0.815000\n",
      "\n",
      "Starting epoch 7 / 10\n",
      "Train accuracy: 0.845000\n",
      "Val accuracy: 0.820000\n",
      "\n",
      "Starting epoch 8 / 10\n",
      "Train accuracy: 0.842500\n",
      "Val accuracy: 0.835000\n",
      "\n",
      "Starting epoch 9 / 10\n",
      "Train accuracy: 0.868750\n",
      "Val accuracy: 0.835000\n",
      "\n",
      "Starting epoch 10 / 10\n",
      "Train accuracy: 0.872500\n",
      "Val accuracy: 0.835000\n",
      "\n",
      "Starting epoch 1 / 10\n",
      "Train accuracy: 0.858750\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 2 / 10\n",
      "Train accuracy: 0.858750\n",
      "Val accuracy: 0.835000\n",
      "\n",
      "Starting epoch 3 / 10\n",
      "Train accuracy: 0.862500\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 4 / 10\n",
      "Train accuracy: 0.858750\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 5 / 10\n",
      "Train accuracy: 0.853750\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 6 / 10\n",
      "Train accuracy: 0.868750\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 7 / 10\n",
      "Train accuracy: 0.863750\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 8 / 10\n",
      "Train accuracy: 0.872500\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 9 / 10\n",
      "Train accuracy: 0.858750\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Starting epoch 10 / 10\n",
      "Train accuracy: 0.867500\n",
      "Val accuracy: 0.840000\n",
      "\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     args = parser.parse_args()\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "a77TciZq6P_U",
    "outputId": "38c60bda-146b-4ac0-dd45-6b77d5db68fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "VGG16.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
